{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import aif360\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset,BankDataset\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,LFR,OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from aif360.examples.common_utils import compute_metrics\n",
    "\n",
    "\n",
    "all_metrics =  [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(df, threshold=600):\n",
    "    drop_cols = [num for num in df.columns if np.sum(df[num] == \"?\") > threshold]\n",
    "    df_drop = df.drop(axis=1, columns=drop_cols)\n",
    "    data = df_drop.replace(\"?\", np.nan)\n",
    "    print(f'Missing values: \\n{data.isna().sum()}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == object:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_nan(df) \n",
    "df[30] = df[30].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in df.columns if df[col].dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StandardDataset(df, \n",
    "                          label_name=label, \n",
    "                          favorable_classes=[favorable_classes], \n",
    "                          protected_attribute_names=[protected_attribute_names], \n",
    "                          privileged_classes=[[privileged_classes]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360.datasets.StandardDataset(df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name='', scores_name='', categorical_features=[], features_to_keep=[], features_to_drop=[], na_values=[], custom_preprocessing=None, metadata=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
    "    \n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def descript_dataset(dataset_orig_train):\n",
    "    # print out some labels, names, etc.\n",
    "    display(Markdown(\"#### Training Dataset shape\"))\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    display(Markdown(\"#### Protected attribute names\"))\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "    print(dataset_orig_train.privileged_protected_attributes, \n",
    "          dataset_orig_train.unprivileged_protected_attributes)\n",
    "    display(Markdown(\"#### Dataset feature names\"))\n",
    "    print(dataset_orig_train.feature_names)\n",
    "    \n",
    "def classify(dataset_orig, model_function, per_train = 0.7):\n",
    "    # Get the dataset and split into train and test\n",
    "    dataset_orig_train, dataset_orig_vt = dataset_orig.split([per_train], shuffle=True)\n",
    "    \n",
    "    # Logistic regression classifier and predictions\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "#     w_train = dataset_orig_train.instance_weights.ravel()\n",
    "    \n",
    "    model = model_function\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # positive class index\n",
    "    pos_ind = np.where(model.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "    dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "    dataset_orig_train_pred.labels = y_train_pred\n",
    "    \n",
    "    return model,dataset_orig_train_pred,dataset_orig_vt,scale_orig,pos_ind\n",
    "\n",
    "def valid_test_classifier(dataset_orig_vt,lmod,scale_orig,pos_ind,per_valid = 0.5):\n",
    "    \n",
    "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([per_valid], shuffle=True)\n",
    "\n",
    "    dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "\n",
    "    X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "    y_valid = dataset_orig_valid_pred.labels\n",
    "    dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "    \n",
    "    return dataset_orig_valid_pred,dataset_orig_test_pred,dataset_orig_test\n",
    "    \n",
    "def get_metrics(dataset_orig_test,dataset_orig_test_pred):\n",
    "    fav_inds = dataset_orig_test_pred.scores > 0.5\n",
    "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "\n",
    "\n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = True)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_german_dataset():\n",
    "    \n",
    "    dataset_orig = GermanDataset(\n",
    "        protected_attribute_names=['age'],         \n",
    "        privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "        features_to_drop=['personal_status', 'sex'],\n",
    "        categorical_features=['status', 'credit_history', 'purpose',\n",
    "                         'savings', 'employment', 'other_debtors', 'property',\n",
    "                         'installment_plans', 'housing', 'skill_level', 'telephone',\n",
    "                         'foreign_worker']# ignore sex-related attributes\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    return dataset_orig\n",
    "\n",
    "def load_bank_dataset():\n",
    "    \n",
    "    dataset_orig = BankDataset(\n",
    "        label_name='y', favorable_classes=['yes'],\n",
    "                     protected_attribute_names=['age'],\n",
    "                     privileged_classes=[lambda x: x >= 25],\n",
    "                     instance_weights_name=None,\n",
    "                     categorical_features=['job', 'marital', 'education', 'default',\n",
    "                         'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "                         'poutcome'],\n",
    "                     features_to_keep=[], features_to_drop=[],\n",
    "                     na_values=[\"unknown\"], custom_preprocessing=None,\n",
    "                     metadata=None)\n",
    "\n",
    "    \n",
    "    return dataset_orig\n",
    "\n",
    "def load_adult_dataset():\n",
    "\n",
    "    \n",
    "    default_mappings = {\n",
    "        'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
    "        'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-white'},\n",
    "                                     {1.0: 'Male', 0.0: 'Female'}]\n",
    "        }\n",
    "    dataset_orig = AdultDataset(label_name='income-per-year',\n",
    "                 favorable_classes=['>50K', '>50K.'],\n",
    "                 protected_attribute_names=['race', 'sex'],\n",
    "                 privileged_classes=[['White'], ['Male']],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=['workclass', 'education',\n",
    "                     'marital-status', 'occupation', 'relationship',\n",
    "                     'native-country'],\n",
    "                 features_to_keep=[], features_to_drop=['fnlwgt'],\n",
    "                 na_values=['?'], custom_preprocessing=None,\n",
    "                 metadata=default_mappings)\n",
    "\n",
    "    \n",
    "    return dataset_orig\n",
    "\n",
    "def load_compas_dataset():\n",
    "    \n",
    "\n",
    "    default_mappings = {\n",
    "        'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "        'protected_attribute_maps': [{0.0: 'Male', 1.0: 'Female'},\n",
    "                                     {1.0: 'Caucasian', 0.0: 'Not Caucasian'}]\n",
    "    }\n",
    "    \n",
    "    dataset_orig = CompasDataset(label_name='two_year_recid', favorable_classes=[0],\n",
    "                 protected_attribute_names=['sex', 'race'],\n",
    "                 privileged_classes=[['Female'], ['Caucasian']],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=['age_cat', 'c_charge_degree',\n",
    "                     'c_charge_desc'],\n",
    "                 features_to_keep=['sex', 'age', 'age_cat', 'race',\n",
    "                     'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "                     'priors_count', 'c_charge_degree', 'c_charge_desc',\n",
    "                     'two_year_recid'],\n",
    "                 features_to_drop=[], na_values=[],\n",
    "                 custom_preprocessing=default_preprocessing,\n",
    "                 metadata=default_mappings)\n",
    "\n",
    "    return dataset_orig\n",
    "    \n",
    "\n",
    "def default_preprocessing(df):\n",
    "    \"\"\"Perform the same preprocessing as the original analysis:\n",
    "    https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "    \"\"\"\n",
    "    return df[(df.days_b_screening_arrest <= 30)\n",
    "            & (df.days_b_screening_arrest >= -30)\n",
    "            & (df.is_recid != -1)\n",
    "            & (df.c_charge_degree != 'O')\n",
    "            & (df.score_text != 'N/A')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 10700 rows removed from BankDataset.\n",
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n",
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german\n",
      "------------------ Sem pré-processamento -----------------\n",
      "age\n",
      "Balanced accuracy = 0.6076\n",
      "Statistical parity difference = -0.1131\n",
      "Disparate impact = 0.8705\n",
      "Average odds difference = -0.0731\n",
      "Equal opportunity difference = -0.1203\n",
      "Theil index = 0.1094\n",
      "------------------ Com pré-processamento -----------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'optimizer' and 'optim_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8efe2ce3b199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rew'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptimPreproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'optimizer' and 'optim_options'"
     ]
    }
   ],
   "source": [
    "datasets = {'german':load_german_dataset(),\n",
    "            'bank':load_bank_dataset(),\n",
    "            'adult':load_adult_dataset(),\n",
    "            'compas':load_compas_dataset()}\n",
    "\n",
    "for name, loader in datasets.items():\n",
    "    \n",
    "    dataset_orig = loader\n",
    "    print(name)\n",
    "    \n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "    X_train = dataset_orig_train.features\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "    X_test = dataset_orig_test.features\n",
    "    y_test = dataset_orig_test.labels.ravel()\n",
    "\n",
    "    models = [SVC(),DecisionTreeClassifier(),LogisticRegression()]\n",
    "\n",
    "    for m in models:\n",
    "\n",
    "        print('------------------ Sem pré-processamento -----------------')\n",
    "\n",
    "\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('model', m)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "        dataset_orig_test_pred = dataset_orig_test.copy()\n",
    "        dataset_orig_test_pred.labels = y_test_pred\n",
    "\n",
    "\n",
    "        for attr in dataset_orig.protected_attribute_names:\n",
    "\n",
    "            print(attr)\n",
    "\n",
    "            idx = dataset_orig.protected_attribute_names.index(attr)\n",
    "            privileged_groups =  [{attr:dataset_orig.privileged_protected_attributes[idx][0]}] \n",
    "            unprivileged_groups = [{attr:dataset_orig.unprivileged_protected_attributes[idx][0]}] \n",
    "\n",
    "            metrics = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                                  unprivileged_groups, privileged_groups,\n",
    "                                                  disp = True)\n",
    "            \n",
    "#     break\n",
    "        print('------------------ Com pré-processamento -----------------')\n",
    "        \n",
    "        attr = dataset_orig.protected_attribute_names[0]\n",
    "        idx = dataset_orig.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_orig.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_orig.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "\n",
    "        pipe = Pipeline([('scaler', StandardScaler()),('rew',OptimPreproc()),('model', m)])\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "        dataset_orig_test_pred = dataset_orig_test.copy()\n",
    "        dataset_orig_test_pred.labels = y_test_pred\n",
    "\n",
    "        metrics = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                              unprivileged_groups, privileged_groups,\n",
    "                                              disp = True)\n",
    "    \n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tentei com Reweighing(unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups), DisparateImpactRemover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = load_german_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = dataset_orig.protected_attribute_names[0]\n",
    "idx = dataset_orig.protected_attribute_names.index(attr)\n",
    "privileged_groups =  [{attr:dataset_orig.privileged_protected_attributes[idx][0]}] \n",
    "unprivileged_groups = [{attr:dataset_orig.unprivileged_protected_attributes[idx][0]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig)\n",
    "dataset_transf_train = RW.transform(dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
